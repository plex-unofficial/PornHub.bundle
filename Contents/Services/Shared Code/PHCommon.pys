import json
import time
import urllib
import urlparse
from collections import OrderedDict

PH_VIDEO_METADATA_JSON_REGEX =	"var flashvars_\d+ = ({[\S\s]+?});"

def GetVideoMetaDataJSON(htmlElement = None, url = None):
	# Get the HTML of the site
	if (htmlElement is None):
		htmlElement =		HTML.ElementFromURL(url)

	htmlString =	HTML.StringFromElement(htmlElement)

	# Search for the video metadata JSON string
	videoMetaDataString = Regex(PH_VIDEO_METADATA_JSON_REGEX).search(htmlString)

	if (videoMetaDataString):
		# If found, convert the JSON string to an object
		return json.loads(videoMetaDataString.group(1))
	else:
		return None

def GetVideos(url):
	# Create an empty list to hold the categories
	videos = []

	# Get the HTML of the site
	html = HTML.ElementFromURL(url)

	# Use xPath to extract a list of divs that contain videos
	videoElements = html.xpath("//li[contains(@class,'videoblock')]")

	# This piece of code is ridiculous. From the best I can gether, the poorly formed HTML on PornHub makes xPath choke at 123 videos. So I rounded it down to 120 and limited the videos to that. This should only affect playlists, but it is a really ridiculous problem
	if (len(videoElements) >= 120):
		videoElements =	videoElements[0:120]

	# Loop through the videos in the page
	for videoElement in videoElements:
		try:
			# Use xPath to extract video details
			video = {
				'title':		videoElement.xpath(".//span[@class='title']/a/text()")[0],
				'url':		videoElement.xpath(".//a/@href")[0],
				'thumbnail':	videoElement.xpath(".//img/@data-mediumthumb")[0]
			}

			# Get the duration of the video
			durationString =	videoElement.xpath(".//var[@class='duration']/text()")[0]

			# Split it into a list separated by colon
			durationArray =	durationString.split(":")

			if (len(durationArray) == 2):
				# Dealing with MM:SS
				minutes =	int(durationArray[0])
				seconds =	int(durationArray[1])

				video["duration"] = (minutes*60 + seconds) * 1000

			elif (len(durationArray) == 3):
				# Dealing with HH:MM:SS... PornHub doesn't do this, but I'll keep it as a backup anyways
				hours =	int(durationArray[0])
				minutes =	int(durationArray[1])
				seconds =	int(durationArray[2])

				video["duration"] = (hours*3600 + minutes * 60 + seconds) * 1000
			else:
				# Set a default duration of 0
				video["duration"] = 0

			videos.append(video)
		except:
				Log("Error encountered with one of the videos... skipping.")
				pass
	return videos

def GetVideoThumbnailURLs(url):
	# Create an empty list to hold the thumbnail URLs
	thumbnailURLs = []

	# Get the video meta data
	videoMetaData = SharedCodeService.PHCommon.GetVideoMetaDataJSON(url=url)

	if (videoMetaData["thumbs"] and videoMetaData["thumbs"]["urlPattern"] != False):

		videoThumbnailsCount =	Regex("S{(\d+)}.jpg$").search(videoMetaData["thumbs"]["urlPattern"])

		if (videoThumbnailsCount):
			videoThumbnailsCountString = videoThumbnailsCount.group(1)

			for i in range(int(videoThumbnailsCountString) + 1):
				thumbnailURLs.append(videoMetaData["thumbs"]["urlPattern"].replace("S{" + videoThumbnailsCountString + "}.jpg", "S" + str(i) + ".jpg"))

	return thumbnailURLs

def GetRelatedVideos(url):
	# Create an empty list to hold the relatedVideos
	relatedVideos = []

	# Get the HTML of the site
	html = HTML.ElementFromURL(url)

	# Use xPath to extract the related videos
	relatedVideoElements = html.xpath("//ul[@id='relatedVideosCenter' or @id='relateRecommendedItems']//li[contains(@class, 'videoblock')]/div[contains(@class, 'wrap')]")

	# Loop through related videos
	for relatedVideoElement in relatedVideoElements:
		relatedVideos.append({
			'title':		relatedVideoElement.xpath("./div[contains(@class, 'thumbnail-info-wrapper')]/span[contains(@class,'title')]/a/text()")[0],
			'url':		relatedVideoElement.xpath("./div[contains(@class, 'thumbnail-info-wrapper')]/span[contains(@class,'title')]/a/@href")[0],
			'thumbnail':	relatedVideoElement.xpath("./div[contains(@class, 'phimage')]/div[contains(@class, 'img')]/a/img/@data-mediumthumb")[0]
		})

	return relatedVideos

def GetPlaylistsContainingVideo(url):
	# Create an empty list to hold the playlists
	playlists = []

	# Get the HTML of the site
	html = HTML.ElementFromURL(url)

	# Use xPath to extract the playlists
	playlistElements = html.xpath("//ul[contains(@class, 'playlist-listingSmall')]/li/div[contains(@class, 'wrap')]")

	# Loop through playlists
	for playlistElement in playlistElements:
		playlists.append({
			'title':		playlistElement.xpath("./div[contains(@class, 'thumbnail-info-wrapper')]/span[contains(@class, 'title')]/a/text()")[0],
			'url':		playlistElement.xpath("./div[contains(@class, 'thumbnail-info-wrapper')]/span[contains(@class, 'title')]/a/@href")[0],
			'thumbnail':	playlistElement.xpath("./div[contains(@class, 'linkWrapper')]/img/@data-mediumthumb")[0]
		})

	return playlists

def GetVideoActions(url):
	# Create an empty list to hold the actions
	actions = []

	# Get the video meta data
	videoMetaData = SharedCodeService.PHCommon.GetVideoMetaDataJSON(url=url)

	if (videoMetaData and videoMetaData["actionTags"]):
		actionTags = videoMetaData["actionTags"].split(",")

		for actionTag in actionTags:
			actionSegments =	actionTag.split(":")

			actions.append({
				'title':		actionSegments[0],
				'timestamp':	time.strftime('%H:%M:%S', time.gmtime(int(actionSegments[1])))
			})

	return actions

# I stole this function from http://stackoverflow.com/questions/2506379/add-params-to-given-url-in-python. It works.
def AddURLParameters (url, params):

	urlParts =	list(urlparse.urlparse(url))

	urlQuery =	dict(urlparse.parse_qsl(urlParts[4]))
	urlQuery.update(params)

	# So... PornHub requires that it's query string parameters are set in the right order... for some reason. This piece of code handles that. It's retarded, but it has to be done
	urlQueryOrder = ['c', 'channelSearch', 'search', 'username', 'o', 't', 'page']

	urlQueryOrdered = OrderedDict()

	for i in urlQueryOrder:
		if i in urlQuery:
			urlQueryOrdered[i] = urlQuery[i]

	urlParts[4] = urllib.urlencode(urlQueryOrdered)

	return urlparse.urlunparse(urlParts)

# I stole this function (and everything I did for search basically) from the RedTube Plex Plugin, this file specifically https://github.com/flownex/RedTube.bundle/blob/master/Contents/Code/PCbfSearch.py
def FormatStringForSearch(query, delimiter):
	query = String.StripTags(str(query))
	query = query.replace('%20',' ')
	query = query.replace('  ',' ')
	query = query.strip(' \t\n\r')
	query = delimiter.join(query.split())

	return query
